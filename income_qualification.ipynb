{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "display(df_train.shape, df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "display(df_test.shape, df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Target'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output variable is 'Target', and is an ordinal variable\n",
    "# if it is oridinal each value then represents a level of severity\n",
    "#1: Extreme Poverty\n",
    "#2: Moderate Poverty\n",
    "#3: Vulnerable Households\n",
    "#4: Non Vulnerable Households\n",
    "\n",
    "df_train['Target'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understand the type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:, ['dependency', 'edjefe', 'edjefa']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[:, ['dependency', 'edjefe', 'edjefa']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'yes' and 'no' with 1 and 0\n",
    "mapping = {'yes': 1, 'no': 0}\n",
    "\n",
    "for col in ['dependency', 'edjefa', 'edjefe']:\n",
    "    df_train[col] = df_train[col].replace(mapping).astype(np.float64)\n",
    "    df_test[col] = df_test[col].replace(mapping).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:, ['dependency', 'edjefe', 'edjefa']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[:, ['dependency', 'edjefe', 'edjefa']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check if there are any biases in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.groupby('Target')['Target'].count())\n",
    "sns.countplot(data=df_train, x='Target')\n",
    "\n",
    "# dataset is clearly biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X_over, y_over = RandomOverSampler().fit_resample(df_train.drop('Target', axis=1), df_train['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_over, y_over], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.groupby('Target')['Target'].count())\n",
    "sns.countplot(data=df_train, x='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['idhogar']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check whether all members of the house have the same poverty level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_groups = df_train.groupby('idhogar')\n",
    "\n",
    "household_same_poverty_level = 0\n",
    "household_diff_poverty_level = 0\n",
    "\n",
    "# iterate over each household group\n",
    "for household_id, household_data in household_groups:\n",
    "    # get the unique poverty levels within the household group\n",
    "    unique_poverty_levels = household_data['Target'].dropna().unique()\n",
    "    if len(unique_poverty_levels) > 1:\n",
    "        # members of the household have different poverty levels\n",
    "        household_diff_poverty_level += 1\n",
    "        # print(f\"Household {household_id} has members with different poverty levels.\")\n",
    "    else:\n",
    "        # members of the household have the same poverty level\n",
    "        household_same_poverty_level += 1\n",
    "        # print(f\"Household {household_id} has members with the same poverty level.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of households with same poverty level = {household_same_poverty_level}')\n",
    "print(f'Total number of households with different poverty levels = {household_diff_poverty_level}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check if there is a house without a family head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by household ID\n",
    "household_groups = df_train.groupby('idhogar')\n",
    "\n",
    "num_households_with_no_family_head = 0\n",
    "\n",
    "for household_id, household_data in household_groups:\n",
    "  if (household_data['parentesco1'] == 1).sum() == 0:\n",
    "    num_households_with_no_family_head += 1\n",
    "    print(f\"Household {household_id} has no family head.\")\n",
    "\n",
    "print('\\n')\n",
    "print(f'Total number of households with a family head = {num_households_with_no_family_head}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_households = df_train['idhogar'].nunique()\n",
    "print(f\"There are {num_households} households in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['parentesco1'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set the poverty level of the members and the head of the house same in a family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_poverty_levels = df_train.loc[df_train['parentesco1'] == 1, ['idhogar', 'Target']].set_index('idhogar')['Target'].to_dict()\n",
    "df_train['Target'] = df_train['idhogar'].map(head_poverty_levels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Count how many null values are existing in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns[df_train.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(columns=['Name of Col', 'Num of Null', 'Dtype', 'Num of Unique'])\n",
    "\n",
    "for i in range(0, len(df_train.columns)):\n",
    "    df_info.loc[i] = [df_train.columns[i],\n",
    "                 df_train[df_train.columns[i]].isna().sum(),\n",
    "                 df_train[df_train.columns[i]].dtypes,\n",
    "                 df_train[df_train.columns[i]].nunique()]\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info[df_info['Num of Null'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the percentage of missing values in each column\n",
    "missing_val_per = round((df_train.isna().sum() / df_train.shape[0]) * 100)\n",
    "missing_val_per\n",
    "\n",
    "# print features that have more than 50% of missing values\n",
    "missing_val_per[missing_val_per > 50]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7b. Create a strategy to handle the missing vlaues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the number of tablets in a household, in this case nan means 0\n",
    "df_train['v18q1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values with 0\n",
    "for data in [df_train, df_test]:\n",
    "  data['v18q1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [df_train, df_test]:\n",
    "    data['rez_esc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2a1 - Monthly rent payment it looks related to tipovivi[i]<br><br>\n",
    "tipovivi1 = own and fully paid house<br>\n",
    "tipovivi2 = own, paying in installments<br>\n",
    "tipovivi3 = rented<br>\n",
    "tipovivi4 = precarious<br>\n",
    "tipovivi5 = other(assigned, borrowed)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train[df_train['v2a1'].isnull()].head(10)\n",
    "data.loc[:,['v2a1', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the nan values in 'v2a1' all coincide with 'tipovivi1'<br>\n",
    "so we will replace them with 0, because if the house is owned<br>\n",
    "no rent has to be paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [df_train, df_test]:\n",
    "  data['v2a1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['meaneduc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaneduc_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "for data in [df_train, df_test]:\n",
    "  data['meaneduc'] = meaneduc_imputer.fit_transform(data[['meaneduc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SQBmeaned'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQBmeaned_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "for data in [df_train, df_test]:\n",
    "  data['SQBmeaned'] = SQBmeaned_imputer.fit_transform(data[['SQBmeaned']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping the squared columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin',\n",
    "        'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']\n",
    "\n",
    "for data in [df_train, df_test]:\n",
    "  data.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7c. Check if the columns for v2a1 and rez_esc are significantly important,<br> if they don't drop them since they have a large amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_plot(feature, title, xlabel):\n",
    "  fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "  sns.displot(feature, kde=True, bins=50)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(xlabel)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plot(df_train['v2a1'], 'Distribution of Monthly Rent Payment', 'Monthly Rent Payment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plot(df_train['rez_esc'], 'Distribution of Years Behind in School', 'Years Behind in School')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for both 'v2a1' and 'rez_esc' is not normally distributed. So we opt for kruskal-wallis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "X1 = df_train[['v2a1']]\n",
    "X2 = df_train[['rez_esc']]\n",
    "y = df_train['Target']\n",
    "\n",
    "H1, pval1 = kruskal(X1[y==1], X1[y==2], X1[y==3], X1[y==4])\n",
    "H2, pval2 = kruskal(X2[y==1], X2[y==2], X2[y==3], X2[y==4])\n",
    "\n",
    "if pval1 < 0.05:\n",
    "  print('The Kruskal-Wallis test for v2a1 is statistically significant. Reject the null hypothesis. ')\n",
    "else:\n",
    "  print('The Kruskal-Wallis test for v2a1 is not statistically significant. Fail to reject the null hypothesis.')\n",
    "\n",
    "if pval2 < 0.05:\n",
    "  print('The Kruskal-Wallis test for rez_esc is statistically significant. Reject the null hypothesis. ')\n",
    "else:\n",
    "  print('The Kruskal-Wallis test for rez_esc is not statistically significant. Fail to reject the null hypothesis.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Remove null value rows of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows in target column that have NaN values\n",
    "df_train = df_train.dropna(subset=['Target'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum().sum()\n",
    "# show the columns that still have miussing values  \n",
    "df_train.columns[df_train.isna().any()]\n",
    "\n",
    "df_train['meaneduc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Predict the accuracy using random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give me the object columns\n",
    "df_train.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the upper triangle of the correlation matrix\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_features = []\n",
    "for col in upper.columns:\n",
    "  if any(abs(upper[col]) > 0.95):\n",
    "    dropped_features.append(col)\n",
    "\n",
    "dropped_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are also dropping 'male', 'Id' and 'idhogar' because they are not useful for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dropped_features.append(items) for items in ['Id', 'idhogar', 'male']]\n",
    "\n",
    "dropped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.drop(dropped_features, axis=1)\n",
    "df_test_copy = df_test.drop(dropped_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_copy.drop(['Target'], axis=1)\n",
    "y = df_train_copy['Target']\n",
    "\n",
    "\n",
    "train_data, val_data, train_target, val_target = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=150, random_state=42, max_depth=50, min_samples_leaf=4, max_features='sqrt')\n",
    "rfc.fit(train_data, train_target)\n",
    "\n",
    "train_score = rfc.score(train_data, train_target)\n",
    "val_score = rfc.score(val_data, val_target)\n",
    "\n",
    "print(\"Test {} Train {} RS {}\".format(val_score,train_score,i))\n",
    "\n",
    "if val_score > train_score:\n",
    "  print(\"Test {} Train {} RS {}\".format(val_score,train_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predict = rfc.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(val_target, val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_target, val_predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = rfc.predict(df_test_copy)\n",
    "df_test_copy['Target'] = test_predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Check the accuracy using a random forest with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=142, shuffle=True)\n",
    "print(cross_val_score(rfc, X, y, cv=kfold, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(rfc, X, y, cv=kfold, scoring='accuracy').mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
